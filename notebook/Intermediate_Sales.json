{
	"name": "Intermediate_Sales",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "Openhackspark",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2"
			}
		},
		"metadata": {
			"saveOutput": true,
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/e6fcac13-b9bc-4f47-af3e-dfa48d717c6d/resourceGroups/mdw-oh-01-westeurope/providers/Microsoft.Synapse/workspaces/openhack-synapse-ec44/bigDataPools/Openhackspark",
				"name": "Openhackspark",
				"type": "Spark",
				"endpoint": "https://openhack-synapse-ec44.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/Openhackspark",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "2.4",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"import uuid\n",
					"import pyspark.sql.functions as F\n",
					"from pyspark.sql.functions import col\n",
					"from pyspark.sql.types import StringType,DateType,LongType,IntegerType,TimestampType"
				],
				"execution_count": 1
			},
			{
				"cell_type": "markdown",
				"source": [
					"# Collect the raw Sales data from all source systems"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"## From Cloud Sales\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"cs_orders = spark.read.csv(\"abfss://rawzone@openhackec44.dfs.core.windows.net/CloudSales/dboOrders.csv\", header='true', inferSchema='true')\n",
					"cs_orderdetails = spark.read.csv(\"abfss://rawzone@openhackec44.dfs.core.windows.net/CloudSales/dboOrderDetails.csv\", header='true', inferSchema='true')\n",
					"\n",
					"cs_sales = cs_orders \\\n",
					".join(cs_orderdetails, on='OrderId', how='left')\n",
					"\n",
					"cs_sales.head(5)\n",
					"\n",
					""
				],
				"execution_count": 2
			},
			{
				"cell_type": "markdown",
				"source": [
					"## From Cloud Streaming\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"cstr_sales=spark.read.csv(\"abfss://rawzone@openhackec44.dfs.core.windows.net/CloudStreaming/dboTransactions.csv\",header='true',inferSchema='true')\n",
					"cstr_sales.head(5)"
				],
				"execution_count": 3
			},
			{
				"cell_type": "markdown",
				"source": [
					"## From Fourth Coffee"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"fc_sales = spark.read.csv(\"abfss://rawzone@openhackec44.dfs.core.windows.net/FouthCoffee/Transactions.csv\", header='true', inferSchema='true')\n",
					"fc_sales.head(1)"
				],
				"execution_count": 4
			},
			{
				"cell_type": "markdown",
				"source": [
					"## From VanArsdel"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"va_sales = spark.read.parquet(\"abfss://rawzone@openhackec44.dfs.core.windows.net/VanArsdelLTD/dboTransactions.parquet\")\n",
					"\n",
					"va_sales.head(3)"
				],
				"execution_count": 5
			},
			{
				"cell_type": "code",
				"source": [
					"cs_sales = cs_sales \\\n",
					".withColumn('OrderDate',F.to_date(col('OrderDate'), 'MM-dd-yyyy')) \\\n",
					".withColumn('SourceSystemId', F.lit('SR'))\n",
					"\n",
					"cstr_sales = cstr_sales \\\n",
					".withColumn('CreatedDate',F.to_date(col('CreatedDate'), 'MM-dd-yyyy')) \\\n",
					".withColumn('SourceSystemId', F.lit('SR'))"
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"source": [
					"cs_sales.head(1)\n",
					""
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"source": [
					"cstr_sales.head(1)"
				],
				"execution_count": 12
			},
			{
				"cell_type": "code",
				"source": [
					"#exemple format date : 20170103\n",
					"  \n",
					"fc_sales = fc_sales \\\n",
					"  .withColumn('RentalDate', F.to_date(col('RentalDate').cast(StringType), 'MM-dd-yyyy')) \\\n",
					"  .withColumn('SourceSystemId', F.lit('FC'))\n",
					"  "
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"source": [
					"fc_sales.printSchema()"
				],
				"execution_count": 33
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Unioning the data\n",
					"\n",
					"### Target schema\n",
					"\n",
					"Looking ahead, we will keep every source record from every catalog, so we don't need to join here.\n",
					"However, we will need to map columns to a consistent schema.\n",
					"\n",
					"```\n",
					"SourceSystemId:              Use the SourceSystemId we added in the previous cell.\n",
					"CatalogId:                   Use a new unique identifier.\n",
					"SourceSystemMovieId:         From Southridge, use the source id. From the others, use the source MovieId.\n",
					"SouthridgeMovieId:           From Southridge, use the source id. From the others, use the source OnlineMovieId.\n",
					"ActorID:                     From Southridge, this is null. From the others, it's the source ActorId.\n",
					"ActorName:                   From Southridge, it's the exploded actor name. From the others, it is the ActorName.\n",
					"ActorGender:                 Southridge does not track this data. The on premises stores have Gender.\n",
					"Title:                       From Southridge, use title. From others, MovieTitle.\n",
					"Genre:                       From Southridge, use genre. From others, Category.\n",
					"Rating:                      Southridge has rating and the others have Rating.\n",
					"RuntimeMinutes:              Southridge has runtime, the others have RunTimeMin.\n",
					"TheatricalReleaseYear:       Southridge has releaseYear. The others don't have this data.\n",
					"PhysicalAvailabilityDate:    Southridge has availabilityDate. The others have ReleaseDate.\n",
					"StreamingAvailabilityDate:   Southridge has streamingAvailabilityDate. The others have no such data, as it does not apply to physical rentals.\n",
					"```\n",
					"\n",
					"### To join, cleanse, drop duplicates, etc. ... or not?\n",
					"\n",
					"At this stage, we want to focus on the **fatal** anomalies that would cause exceptions in downstream processing;\n",
					"e.g., inconsistent data types or formats.\n",
					"If we were loading this data directly into a final reporting schema, we would likely apply additional cleansing such as:\n",
					"\n",
					"- Look for and eliminate typos, e.g., PGg instead of PG\n",
					"- Normalize capitalization of titles, names, ratings, etc.\n",
					"- Look for and resolve conflicts in matched movies, e.g., Southridge thinks Mysterious Cube is a G-rated family movie while VanArsdel, Ltd. had it as a PG-13 rated Comedy\n",
					"- Look for variations in actor names and choose one to use consistently throughout the reporting schema, e.g., Vivica A. Fox vs Vivica Fox\n",
					"- Drop duplicates\n",
					"- etc., etc., etc.\n",
					"\n",
					"However, if we perform these operations now, then we may eliminate the opportunity to discover previously unrecognized value in the data.\n",
					"As a contrived example, consider a possibility that some actors and actresses would occassionally use their middle initial, but sometimes would not.\n",
					"Now, imagine that data scientists uncover a trend where films are more marketable when the cast does use their middle initial versus when they do not.\n",
					"Or maybe that only holds true in the Drama genre, but it does not hold in Family movies.\n",
					"If we have already chosen the person's \"usual\" billing and only kept that version in our conformed dataset,\n",
					"the the data scientists would never be able to see this."
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# This is used in the following cells to create a new unique identifier\n",
					"\n",
					"uuidUdf = F.udf(lambda : str(uuid.uuid4()), StringType())"
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"source": [
					"sr_conformed = sr_catalog \\\n",
					"  .select([ \\\n",
					"    col(\"SourceSystemId\"), \\\n",
					"    col(\"id\").alias(\"SourceSystemMovieId\"), \\\n",
					"    col(\"id\").alias(\"SouthridgeMovieId\"), \\\n",
					"    col(\"availabilityDate\").cast(TimestampType()).alias(\"PhysicalAvailabilityDate\"), \\\n",
					"    col(\"streamingAvailabilityDate\").cast(TimestampType()).alias(\"StreamingAvailabilityDate\"), \\\n",
					"    col(\"genre\").alias(\"Genre\"), \\\n",
					"    col(\"title\").alias(\"Title\"), \\\n",
					"    col(\"rating\").alias(\"Rating\"), \\\n",
					"    col(\"runtime\").alias(\"RuntimeMinutes\"), \\\n",
					"    col(\"releaseYear\").alias(\"TheatricalReleaseYear\"), \\\n",
					"    sr_catalog[\"actor.name\"].alias(\"ActorName\")]) \\\n",
					"  .withColumn(\"ActorId\", F.lit(None).cast(StringType())) \\\n",
					"  .withColumn(\"ActorGender\", F.lit(None).cast(StringType())) \\\n",
					"  .withColumn(\"CatalogId\", uuidUdf())"
				],
				"execution_count": 14
			},
			{
				"cell_type": "code",
				"source": [
					"# VanArsdel and Fourth Coffee are extremely similar\n",
					"\n",
					"va_conformed = va_catalog \\\n",
					"  .select([ \\\n",
					"    col(\"SourceSystemId\"), \\\n",
					"    col(\"MovieID\").alias(\"SourceSystemMovieId\"), \\\n",
					"    col(\"OnlineMovieID\").alias(\"SouthridgeMovieId\"), \\\n",
					"    col(\"ReleaseDate\").cast(TimestampType()).alias(\"PhysicalAvailabilityDate\"), \\\n",
					"    F.lit(None).cast(TimestampType()).alias(\"StreamingAvailabilityDate\"), \\\n",
					"    col(\"Category\").alias(\"Genre\"), \\\n",
					"    col(\"MovieTitle\").alias(\"Title\"), \\\n",
					"    col(\"Rating\").alias(\"Rating\"), \\\n",
					"    col(\"RunTimeMin\").cast(LongType()).alias(\"RuntimeMinutes\"), \\\n",
					"    F.lit(None).cast(LongType()).alias(\"TheatricalReleaseYear\"), \\\n",
					"    col(\"ActorName\"), \\\n",
					"    col(\"MovieActorID\").alias(\"ActorID\"), \\\n",
					"    col(\"Gender\").alias(\"ActorGender\")]) \\\n",
					"  .withColumn(\"CatalogId\", uuidUdf())\n",
					"\n",
					"fc_conformed = fc_catalog \\\n",
					"  .select([ \\\n",
					"    col(\"SourceSystemId\"), \\\n",
					"    col(\"MovieID\").alias(\"SourceSystemMovieId\"), \\\n",
					"    col(\"OnlineMovieID\").alias(\"SouthridgeMovieId\"), \\\n",
					"    col(\"ReleaseDate\").cast(TimestampType()).alias(\"PhysicalAvailabilityDate\"), \\\n",
					"    F.lit(None).cast(TimestampType()).alias(\"StreamingAvailabilityDate\"), \\\n",
					"    col(\"Category\").alias(\"Genre\"), \\\n",
					"    col(\"MovieTitle\").alias(\"Title\"), \\\n",
					"    col(\"Rating\").alias(\"Rating\"), \\\n",
					"    col(\"RunTimeMin\").cast(LongType()).alias(\"RuntimeMinutes\"), \\\n",
					"    F.lit(None).cast(LongType()).alias(\"TheatricalReleaseYear\"), \\\n",
					"    col(\"ActorName\"), \\\n",
					"    col(\"MovieActorID\").alias(\"ActorID\"), \\\n",
					"    col(\"Gender\").alias(\"ActorGender\")]) \\\n",
					"  .withColumn(\"CatalogId\", uuidUdf())"
				],
				"execution_count": 15
			},
			{
				"cell_type": "code",
				"source": [
					"# The full catalog is now a straightforward union\n",
					"\n",
					"full_catalog = sr_conformed.union(va_conformed).union(fc_conformed)\n",
					"full_catalog.write.mode(\"overwrite\").parquet(\"abfss://rawzone@openhackec44.dfs.core.windows.net/Normalized/catalog\")"
				],
				"execution_count": 16
			},
			{
				"cell_type": "code",
				"source": [
					"# Let's rehydrate and confirm that everything checks out\n",
					"\n",
					"rehydrated_catalog = spark.read.parquet(\"abfss://rawzone@openhackec44.dfs.core.windows.net/Normalized/catalog\")\n",
					"\n",
					"sr_rehydrated = rehydrated_catalog.filter(\"SourceSystemID=='SR'\")\n",
					"\n",
					"sr_actors_per_movie = sr_rehydrated \\\n",
					"  .groupby(col('SourceSystemMovieId')) \\\n",
					"  .agg(F.count(F.lit(1)).alias('ActorCount'))\n",
					"\n",
					"print('The number of rows from Southridge is ', sr_rehydrated.count())\n",
					"print('The number of distinct movies from Southridge is', sr_actors_per_movie.count())\n",
					"print(sr_actors_per_movie.limit(1).collect())"
				],
				"execution_count": 18
			}
		]
	}
}